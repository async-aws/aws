---
layout: client
category: clients
name: S3
package: async-aws/s3
---

The client supports presign of requests to be able to pass the URL to an unauthorized
party so they can download a file within the next X minutes. Read more about presign
[here](/features/presign.md).

> **Note**: There is a [SimpleS3Client](/integration/simple-s3.md) that might be easier to work with for common use cases.

## Usage

### Upload files

If you want to upload a 1 Gb file, you really don't want to put that file in memory
before uploading. You want to do it a smarter way. AsyncAws allow you to upload
files using a string, resource, closure or a iterable. See the following examples:

```php
use AsyncAws\S3\S3Client;

$s3 = new S3Client();

// Upload plain text
$s3->putObject([
    'Bucket' => 'my-company-website',
    'Key' => 'robots.txt',
    'Body' => "User-agent: *\nDisallow:",
]);

// Upload with stream
$resource = \fopen('/path/to/big/file', 'r');
$s3->putObject([
    'Bucket' => 'my-company-website',
    'Key' => 'file.jpg',
    'Body' => $resource,
]);

// Upload with Closure
$fp = \fopen('/path/to/big/file', 'r');
$s3->putObject([
    'Bucket' => 'my-company-website',
    'Key' => 'file.jpg',
    'ContentLength' => filesize('/path/to/big/file'), // This is important
    'Body' => static function(int $length) use ($fp): string {
        return fread($fp, $length);
    },
]);

// Upload with an iterable
$files = ['/path/to/file1.txt', '/path/to/file2.txt'];
$s3->putObject([
    'Bucket' => 'my-company-website',
    'Key' => 'file_merged.jpg',
    'ContentLength' => array_sum(array_map('filesize', $files)), // This is important
    'Body' => (static function() use($files): iterable {
        foreach ($files as $file) {
            yield file_get_contents($file);
        }
    })(),
]);
```

When using a `Closure`, it's important to provide the property `ContentLength`.
This information is required by AWS, and cannot be guessed by AsyncAws.
If `ContentLength` is absent, AsyncAws will read the output before sending the
request which could have a performance impact.


### Download files

When you download a file from S3, AsyncAws gives you a `ResultStream` which
can be used as a string, as a resource, or iterated over. This allows you to handle
larger files without having them in memory.

```
// download a file and use it directly as string
$result = $s3->getObject([
    'Bucket' => 'my-company-website',
    'Key' => 'metadata.json',
]);
$metadata = json_decode($result->getBody()->getContentAsString());

// download a big file and save it efficiently
$result = $s3->getObject([
    'Bucket' => 'my-company-website',
    'Key' => 'bunny.mkv',
]);
$fp = fopen('/path/to/big_file.mkv', 'wb');
stream_copy_to_stream($result->getBody()->getContentAsResource(), $fp);

// use an iterable to perform some business logic on chunks while downloading (or show a progress bar)
$result = $s3->getObject([
    'Bucket' => 'my-company-website',
    'Key' => 'orders.csv',
]);
$fp = fopen('/path/to/orders.csv', 'wb');
foreach ($result->getBody()->getChunks() as $chunk) {
    fwrite($fp, $chunk);
    $progress->advance();
}
```

### Add tags to a bucket

You can add tags to your buckets to help you find related resources in the AWS cost explorer; eg all AWS resources tagged
with `environment = staging` would show you the amount you're spending on your pre-prod environment each month

```
$client->putBucketTagging(
    new PutBucketTaggingRequest([
        'Bucket' => 'my-website-assets-bucket',

        'Tagging' => new Tagging([
            'TagSet' => [
                new Tag([
                    'Key' => 'environment',
                    'Value' => 'production',
                ]),
                new Tag([
                    'Key' => 'project-name',
                    'Value' => 'unicorn',
                ])
            ],
        ]),
    ])
);
```

### Managing object tags

You can associate multiple key-value pairs (tags) with each of your S3 objects, with the ability to change them at any time.
The tags can be used to manage and control access, set up lifecycle rules, customize S3 Storage Class Analysis, and filter CloudWatch metrics.

Learn more at [Simplify your data lifecycle by using object tags with Amazon S3 Lifecycle](https://aws.amazon.com/blogs/storage/simplify-your-data-lifecycle-by-using-object-tags-with-amazon-s3-lifecycle/)

```php
$client->putObjectTagging(
    new PutObjectTaggingRequest([
        'Bucket' => 'examplebucket',
        'Key' => 'baz/HappyFace.jpg',
        'Tagging' => new Tagging([
            'TagSet' => [
                new Tag([
                    'Key' => 'expire-after-30-days',
                    'Value' => '1',
                ])
            ],
        ]),
    ])
);

$client->getObjectTagging(
    new GetObjectTaggingRequest([
        'Bucket' => 'examplebucket',
        'Key' => 'baz/HappyFace.jpg',
    ])
);

$client->deleteObjectTagging(
    new DeleteObjectTaggingRequest([
        'Bucket' => 'examplebucket',
        'Key' => 'baz/HappyFace.jpg',
    ])
);
```

## Virtual Hosted-Style Requests

When calling AWS endpoints, AsyncAws uses [Virtual Hosted-Style Requests](https://docs.aws.amazon.com/AmazonS3/latest/dev/VirtualHosting.html):
The bucket name is part of the endpoint's host. To change this behavior, and use
"path styled endpoints" instead, set `pathStyleEndpoint` parameter to `true` when
initializing the client.

```php
use AsyncAws\S3\S3Client;

$s3 = new S3Client(['pathStyleEndpoint' => true]);
```

## Chunked body

When sending data to AWS endpoints, AsyncAws split the content in multiple
chunks. This improves UX by avoiding reading the file twice (required
[to compute the signature](https://docs.aws.amazon.com/AmazonS3/latest/API/sig-v4-header-based-auth.html)
) which could be a performance issue when file is really big, or the uploaded
content is not a file (ie. streamed from an HTTP request). But some 3rd party
services like Openstack Swift, pretending being "S3-compatible" does not
support chunked body. To change this behavior, set `sendChunkedBody` parameter
to `false` when initializing the client.

```php
use AsyncAws\S3\S3Client;

$s3 = new S3Client(['sendChunkedBody' => false]);
```

## Non-AWS S3 endpoints

To use the `S3Client` with example Digital Oceans' Spaces, you need to initialize
the `S3Client` with your endpoint.

```php
$s3 = new S3Client([
    'endpoint' => 'https://fra1.digitaloceanspaces.com',
    'pathStyleEndpoint' => true,
]);
```
